{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TxxL9UEaqO9"
      },
      "source": [
        "# **Clinical Data Science and Machine Learning with Python**\n",
        "\n",
        "## **Day 2**\n",
        "\n",
        "**Instructor**: Teresa Krieger, BIH/Charit√© (teresa.krieger@charite.de)\n",
        "\n",
        "**Content**:\n",
        "\n",
        "1.   References\n",
        "2.   Library imports and data download\n",
        "3.   Data preparation\n",
        "4.   Model building\n",
        "5.   Model training\n",
        "6.   Model evaluation\n",
        "7.   Model prediction\n",
        "8.   Optional: More MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4ROcAPaqPB"
      },
      "source": [
        "---\n",
        "## **1. References**\n",
        "\n",
        "In this course, we will use Python 3.6 (default in Colab as of February 2021).\n",
        "The following documentation and links might be useful to you:\n",
        "\n",
        "- Deep Learning:\n",
        "  - https://www.deeplearningbook.org/\n",
        "- Tensorflow and Keras:\n",
        "  - https://www.tensorflow.org/tutorials/\n",
        "  - https://keras.io/guides/\n",
        "- Source of the pneumonia X-ray dataset:\n",
        "  - https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
        "- We will loosely follow these tutorials:\n",
        "  - https://www.kaggle.com/code/amyjang/tensorflow-pneumonia-classification-on-x-rays/notebook\n",
        "\n",
        "You can also take a look at [this](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) machine learning series on Youtube, where you can learn more about e.g. bias and variance, regression, and other common machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Seipdq1Owq"
      },
      "source": [
        "---\n",
        "## **2. Library imports and data download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzGW_2hDCS1e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.utils as image\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from google.colab import files\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN9ygNZMx-W-"
      },
      "source": [
        "In this session, we will be working with chest X-ray images from patients with and without pneumonia. This data is available on Kaggle. Before we can download it, we need to set up a connection to Kaggle in our colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b8xdW9Jz7ST"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!wget -O kaggle.json https://www.dropbox.com/s/ewjoj1ge5u130m9/kaggle.json?dl=0\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3dhn08u0_5X"
      },
      "source": [
        "Now we can download the data from Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQvWxd7kyAvS"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nnj3SfF1HSl"
      },
      "source": [
        "The dataset is organised into 3 folders (train, test, val) and contains subfolders for each image category (PNEUMONIA/NORMAL). There are 5,863 X-Ray images (JPEG) across the two categories. We still need to unzip the compressed data and store the folder names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pQ8h2_DyQY1"
      },
      "outputs": [],
      "source": [
        "# Extract compressed data\n",
        "with zipfile.ZipFile('chest-xray-pneumonia.zip', mode='r') as zf:   # Here, mode = 'r' means we are reading the zip file\n",
        "  zf.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaXHfIvT3_Ku"
      },
      "outputs": [],
      "source": [
        "# Define the folder paths:\n",
        "img_dir = os.path.join(os.getcwd(), 'chest_xray')   # This is the parent directory\n",
        "train_img_dir = os.path.join(img_dir, 'train')\n",
        "test_img_dir = os.path.join(img_dir, 'test')\n",
        "val_img_dir = os.path.join(img_dir, 'val')\n",
        "\n",
        "# Print the paths\n",
        "print('Parent directory for images: '+img_dir)\n",
        "print('Directory for training images: '+train_img_dir)\n",
        "print('Directory for test images: '+test_img_dir)\n",
        "print('Directory for validation images: '+val_img_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would now like to take a look at some example images from the NORMAL and PNEUMONIA categories inside our training data folder."
      ],
      "metadata": {
        "id": "u0sSm0skRS-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples_normal=os.listdir(train_img_dir+\"/NORMAL/\")[0:4]\n",
        "samples_pneumonia=os.listdir(train_img_dir+\"/PNEUMONIA/\")[0:4]\n",
        "f, ax = plt.subplots(2,4, figsize=(30,10))\n",
        "for i in range(4):\n",
        "    img = plt.imread(train_img_dir+\"/NORMAL/\"+samples_normal[i])\n",
        "    ax[0,i].imshow(img, cmap='gray')\n",
        "    ax[0,i].set_title(\"Normal\")\n",
        "for i in range(4):\n",
        "    img = plt.imread(train_img_dir+\"/PNEUMONIA/\"+samples_pneumonia[i])\n",
        "    ax[1,i].imshow(img, cmap='gray')\n",
        "    ax[1,i].set_title(\"Pneumonia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YlLVZN2QRttS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn7MGAvG47JO"
      },
      "source": [
        "---\n",
        "## **3. Data preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxcFyD649mJ"
      },
      "source": [
        "To prepare the images for processing, we will use the `ImageDataGenerator` function from `Keras`. This function automatically generates batches of image data for training and testing our model. Moreover, it can perform real-time data augmentation, for example by introducing random rotations and vertical or horizontal flips. You can find out more in the documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator).\n",
        "\n",
        "For now, we will only apply the `rescale` argument to transform all images to a [0...1] grayscale range instead of [0...255] as is common for RGB images. The generator essentially reads images from the source folders in batches when they are required during training and evaluation. We will therefore set up separate instances for training, validation and testing:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBJYfeDo4qoM"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/train/',\n",
        "    target_size = (300,300),   # dimensions to which all images will be resized (in pixels)\n",
        "    batch_size = 128,          # data is loaded in batches\n",
        "    class_mode = 'binary'      # refers to the binary labels (0/1)\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/test/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
        "    'chest_xray/val/',\n",
        "    target_size = (300, 300),\n",
        "    batch_size = 128,\n",
        "    class_mode = 'binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBQF0ovWU5bP"
      },
      "source": [
        "---\n",
        "## **4. Model building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKCKbFEYrFTx"
      },
      "source": [
        "The model we are going to build consists of several components:\n",
        "\n",
        "*   **tf.keras.layers.Conv2D()**: the convolution layer which abstracts images features\n",
        "*   **tf.keras.layers.MaxPooling2D()**: a layer to reduce the information in an image while maintaining features\n",
        "*   **tf.keras.layers.Flatten()**: flattens the result into a one-dimensional array\n",
        "*   **tf.keras.layers.Dense()**: a densely connected layer\n",
        "\n",
        "We will build a four-layer convolutional neural network in which each layer consists of a Conv2D() and a MaxPooling2D() step. Then, the output of the final convolutional layer will be flattened and fit to fully connected neurons. A dropout layer is added to avoid overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_6ikMm5sflP"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # Note the input shape is the size of the image (300 x 300 px) x 3 colours\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Flatten output\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Densely connected hidden layer with 512 neurons\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    # Dropout layer\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    # One output neuron with a sigmoid activation function -\n",
        "    # this will contain a value from 0 ('normal') to 1 ('pneumonia')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmAGCFx-3E8b"
      },
      "source": [
        "We can inspect the architecture of our model by printing a summary as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Fgvk9CshP4"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\"\n",
        ")"
      ],
      "metadata": {
        "id": "aOOvybvXg3zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Hrrnrsqv3A"
      },
      "source": [
        "Additionally, before the model is fitted for training, it is necessary to configure the specifications as follows:\n",
        "\n",
        "*   **loss**: with a sigmoid activation function in the final step, we select `binary_crossentropy` as the loss function\n",
        "*   **optimizer**: `RMSprop` (Root Mean Square Propagation) with a learning rate of 0.001 will be used\n",
        "*   **metrics**: we will use `accuracy` as our metric to evaluate the prediction accuracy on every epoch\n",
        "\n",
        "We can now compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vIpy4YR2rZ0"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhRg0cq656Oa"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxyVGtx06FHz"
      },
      "source": [
        "**Exercise 1**: Define a different sequential model for our images (e.g. using a different number of convolutions and adding one or two more dropout layers). Store this as variable `model2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WivA8_f455hq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFa3FDfS8zg8"
      },
      "source": [
        "---\n",
        "## **5. Model training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhrsxPiF7aiY"
      },
      "source": [
        "Now we are ready to train our model. We will train for 25 epochs and store our progress in `history`. Note that this might take a few minutes - time for some tea or coffee!\n",
        "\n",
        "**Please note:**\n",
        "If you're training your own `model2`, you might want to change the name of this new variable to `history2` so that you don't overwrite it with the example model's `history` later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApgFjCYT7OG5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs = 25\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `history` object contains the `history.history` attribute, which is a record of training loss values and metrics values at successive epochs - this is what we're interested in here (again, replace by `history2` if necessary)."
      ],
      "metadata": {
        "id": "qKnRRz53tC9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = history.history"
      ],
      "metadata": {
        "id": "k9XQO2zSs_TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we can save our model and the training history:"
      ],
      "metadata": {
        "id": "Y9xEaiCvk5EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "tf.keras.saving.save_model(\n",
        "    model, 'trained_model.h5', overwrite=True, save_format='h5'\n",
        ")\n",
        "\n",
        "# Save training history\n",
        "with open('training_history', 'wb') as file_pi:\n",
        "  pickle.dump(history, file_pi)"
      ],
      "metadata": {
        "id": "V6DN8Qxvk9XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU1-aRZaAXnH"
      },
      "source": [
        "**Taking too long?** If you've finished your tea or coffee but the above is still not done, you can also interrupt execution of the cell by clicking on `Runtime > Interrupt execution` in the top menu. Now you can just download the trained model as well as the training history by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and training history\n",
        "!wget -O trained_model.h5 https://www.dropbox.com/scl/fi/syngj8c2lijfoo228zl0n/trained_model.h5?rlkey=ec2h2ejk976j065s5rqg5kdvm&dl=0\n",
        "model = tf.keras.saving.load_model('trained_model.h5')\n",
        "\n",
        "!wget -O training_history.pickle https://www.dropbox.com/scl/fi/wxdtgif7kcrgrh08d94ph/training_history?rlkey=yhw2muwjvwzpr71146ks0dxxm&dl=0\n",
        "file_to_read = open('training_history.pickle', 'rb')\n",
        "history = pickle.load(file_to_read)\n",
        "file_to_read.close()"
      ],
      "metadata": {
        "id": "sU8GImBSpuBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHzSGLGeqU7_"
      },
      "source": [
        "---\n",
        "## **6. Model evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHiW6pFo_9We"
      },
      "source": [
        "To evaluate our model, we can plot the accuracy as a function of training epochs for our training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7H4BzqO_X_R"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTMc5JGOOutp"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_t86ELtOutr"
      },
      "source": [
        "**Exercise 1**: Plot the loss instead of the accuracy for training and validation data. Place the legend in the upper right corner of the plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krNRYiRwOuts"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Kn0axUEAJI"
      },
      "source": [
        "---\n",
        "## **7. Model prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrM3Cu6OFsDf"
      },
      "source": [
        "So how does our model perform on unseen data? We can use the `model.evaluate` function to check this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q8qexSGFrvl"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_generator)\n",
        "print('loss for test data :', result[0])\n",
        "print('accuracy for test data :', result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwR7BI_Gl7n"
      },
      "source": [
        "You will probably receive a prediction accuracy upwards of 80%, which is not bad for such a simple model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTcKMmnPG2pk"
      },
      "source": [
        "Now our model is ready to make predictions! This can be done with the `model.predict` function. To predict whether a given image corresponds to a patient with or without pneumonia, we first need to download the image file and feed it into the `model.predict` function. For simplicity, we will use a file from the test data set, but we could of course also use our model for any other chest X-ray!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_mvhL0D-1o"
      },
      "outputs": [],
      "source": [
        "!wget -O test_image_1.jpeg https://www.dropbox.com/s/z2dwy069smbrtym/test_image_1.jpeg?dl=0\n",
        "path = 'test_image_1.jpeg'  # File path to an image from the test data set\n",
        "img = tf.keras.utils.load_img(path, target_size=(300,300))   # Load image\n",
        "x = tf.keras.utils.img_to_array(img)     # Turn image into array\n",
        "x = x/255 # Scale\n",
        "x = np.expand_dims(x, axis=0)   # Add one dimension to match the input size expected by our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjoLy7T0Kx0G"
      },
      "outputs": [],
      "source": [
        "prob_pneumonia = model.predict(x)\n",
        "prob_pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooWY7lOknuH"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMh_LLQ6XJEz"
      },
      "source": [
        "**Exercise 1**: The variable `prob_pneumonia` gives the probability that the image comes from a pneumonia patient. Write a few lines of code to print 'The patient has pneumonia' if this probability is greater than 50%, and 'The patient does not have pneumonia' otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikg7piuDXQSg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ2baKahXaRR"
      },
      "source": [
        "**Exercise 2**: As (future) medical doctors, you might also want to take a look at the image yourself. You can display it using the `imshow` function of `matplotlib` as shown below. Do you agree with your model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMAQIBeGOPTk"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUpkAxjrU9ec"
      },
      "source": [
        "**Exercise 3**: If you're still feeling motivated, you can repeat the evaluation for the image file called `test_image_2.jpeg` which you can download from https://www.dropbox.com/s/z471e1sbeac29g7/test_image_2.jpeg?dl=0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmsFrKYg6pqE"
      },
      "source": [
        "**Exercise 4:** If you're STILL feeling motivated and you have some time to spare this afternoon: What happens if, instead of our model with five convolutions, you use your model with only three convolutions (`model2`)? Does this affect the performance of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWqA8NKd7Ewp"
      },
      "source": [
        "---\n",
        "## **8. Optional: More MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmee_y0G94m7"
      },
      "source": [
        "Here you can try out how different network architectures and training parameters affect the performance of a deep learning model for the MNIST dataset. We will start with the following architecture:\n",
        "*   input shape 28√ó28√ó1 (the size of the images),\n",
        "*   1st convolutional layer with 64 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "*   dropout layer which drops 20% of the input units,\n",
        "*   2nd convolutional layer with 32 filters, kernel size (3,3), stride (1,1) and ReLu activations,\n",
        "*   flatten layer,\n",
        "*   dense output layer with 10 units and softmax activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1-MzujF-Qfe"
      },
      "source": [
        "**Load and prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vFqxc8AD94aO"
      },
      "outputs": [],
      "source": [
        "# Import the MNIST dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST images and labels and normalise (range 0 to 1) image data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # 60,000 training + 10,000 test images/labels\n",
        "X_train = X_train / 255.0\n",
        "X_test  = X_test / 255.0\n",
        "\n",
        "# Reshape dataset to have a single channel\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)) # The CNN requires this layout (batch_size, height, width, n_channels)\n",
        "\n",
        "# One-hot encode target values (i.e. make all the values 0 or 1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoIimFom-gWP"
      },
      "source": [
        "**Build model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eh0Jv9Hs7EK0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28,1)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(Flatten()) # This flattens your image with width and height into a vector of length widht*height.\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02Qnhtg-rrQ"
      },
      "source": [
        "**Compile model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G4-KlOTd6km7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Loss function\n",
        "loss = CategoricalCrossentropy()\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTIQcz6N_g8M"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kn6fA1w2_CFM"
      },
      "outputs": [],
      "source": [
        "# Define number of epochs and batch size\n",
        "epochs = 5\n",
        "batch_size = 512\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(x=X_train, y=y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMvOdfh1-u0K"
      },
      "source": [
        "**Plot loss and accuracy as a function of epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ISmWKXVy_Kr-"
      },
      "outputs": [],
      "source": [
        "n_epochs = np.arange(0,epochs)\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,16))\n",
        "ax1.plot(n_epochs, history.history['loss'], label='training loss')\n",
        "ax1.plot(n_epochs, history.history['val_loss'], label='validation loss')\n",
        "ax1.set_ylim(-0.05,1.05)\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(n_epochs, history.history['accuracy'], label='training accuracy')\n",
        "ax2.plot(n_epochs, history.history['val_accuracy'], label='validation accuracy')\n",
        "ax2.set_ylim(-0.05,1.05)\n",
        "ax2.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5WsRka_nCk"
      },
      "source": [
        "**Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W37EqAu7_moq"
      },
      "outputs": [],
      "source": [
        "loss_and_metrics = model.evaluate(X_test, y_test,\n",
        "                                  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPwXxwv7AHhb"
      },
      "source": [
        "---\n",
        "#### **_Your turn_: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQC6E8gTAUWh"
      },
      "source": [
        "**Exercise 1:** Try changing the architecture of your model, e.g. by adding layers or changing the type of layers. How does this affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssZH4DbyAoMt"
      },
      "source": [
        "**Exercise 2:** Try changing the training parameters of your model, e.g. the number of epochs or the batch size. How does this affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxF7RTDcwRgR"
      },
      "source": [
        "#**Well done!**\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cPwXxwv7AHhb"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
